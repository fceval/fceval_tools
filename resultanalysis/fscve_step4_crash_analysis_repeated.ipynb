{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# calculate tables of crash uniques\n",
    "benchmark = \"cflow\"\n",
    "expids = 5\n",
    "fc = \"fcb\"\n",
    "benchmarks = {\"cflow\", \"jq\", \"mp42aac\"} # \"exiv2\",\n",
    "fcs = {\"fca\", \"fcb\"}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  benchmark fuzzer_combination  experiment_id  count\n",
      "0     cflow                fca              1    743\n",
      "1     cflow                fca              2    454\n",
      "2     cflow                fca              3    671\n",
      "3     cflow                fca              4    516\n",
      "4     cflow                fca              5    485\n",
      "  benchmark fuzzer_combination  experiment_id  count\n",
      "0     cflow                fcb              1    326\n",
      "1     cflow                fcb              2    112\n",
      "2     cflow                fcb              3    577\n",
      "3     cflow                fcb              4    493\n",
      "4     cflow                fcb              5    237\n"
     ]
    }
   ],
   "source": [
    "for fc in fcs:\n",
    "    dfs = []\n",
    "    for expid in range(0,expids):\n",
    "        df = pd.read_csv(f\"csv/fscve_unique_crashes_{benchmark}_{fc}_{expid+1}.csv\")\n",
    "        dfs.append(df)\n",
    "    df_unique_crashes_all = pd.concat(dfs, ignore_index=True)\n",
    "    cols_to_keep = [\"benchmark\",\"fuzzer_combination\",\"experiment_id\",\"count\"]\n",
    "    df_unique_crashes_all.drop(df_unique_crashes_all.columns.difference(cols_to_keep), axis=1, inplace=True)\n",
    "    print(df_unique_crashes_all)\n",
    "    path_unique_crashes_all_csv = f\"csv/fscve_unique_crashes_{benchmark}_{fc}_all.csv\"\n",
    "    df_unique_crashes_all.to_csv(path_unique_crashes_all_csv)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "     benchmark fuzzer_combination  \\\n",
      "0        cflow                fca   \n",
      "1        cflow                fca   \n",
      "2        cflow                fca   \n",
      "3        cflow                fca   \n",
      "4        cflow                fca   \n",
      "...        ...                ...   \n",
      "4597     cflow                fcb   \n",
      "4598     cflow                fcb   \n",
      "4599     cflow                fcb   \n",
      "4600     cflow                fcb   \n",
      "4601     cflow                fcb   \n",
      "\n",
      "                                          testcase_hash  \n",
      "0     6efe29740e288d39419180ed180ad504301a5f812b4bb0...  \n",
      "1     c0933a6d225bc6ffb4e2bcaad34d0b4581a768290f8dfb...  \n",
      "2     9d8e83635e429cb0ca9edac85d61940ef53f1b4bdf2c06...  \n",
      "3     5002388564e8e820387f613162dd25ffd831d40fb58364...  \n",
      "4     b7a11deb43440f0efc8f48ab3699a90fc5d149c6d954d2...  \n",
      "...                                                 ...  \n",
      "4597  5d7938b1fc66b6f1dce54e9609e2a6e0fc3a3d6da1e142...  \n",
      "4598  a381eb018f15c6cc35f2958033782563fba421bba33979...  \n",
      "4599  7af7d52a1914dcf88ea9bf6e1f961a17c0b63730cf6174...  \n",
      "4600  2a4a3e9b29a20fc5192c58f94a241581fe5244ac64e45b...  \n",
      "4601  50d6b7fc7c9351b81e9afdff1e57f7f0ce385fd79f40f8...  \n",
      "\n",
      "[4602 rows x 3 columns]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#calc total unique crashes of a fuzzer combination on a benchmark\n",
    "dfres = pd.DataFrame()\n",
    "df = pd.DataFrame()\n",
    "cols_to_keep = [\"benchmark\",\"fuzzer_combination\",\"testcase_hash\"]\n",
    "df_results = []\n",
    "#calc all data of a fuzzer combination on one benchmark\n",
    "for fc in fcs:\n",
    "    dfs = []\n",
    "    for expid in range(0,expids):\n",
    "        df = pd.read_csv(f\"csv/fscve_unique_crashes_step7metric1_{benchmark}_{fc}_{expid+1}.csv\")\n",
    "        dfs.append(df)\n",
    "    dfres = pd.concat(dfs, ignore_index=True)\n",
    "    dfres.drop(dfres.columns.difference(cols_to_keep), axis=1, inplace=True)\n",
    "    #print(dfres)\n",
    "    # print(dfres.shape[1])\n",
    "    dfres =  dfres.drop_duplicates([\"testcase_hash\"])\n",
    "    # print(dfres.shape[1])\n",
    "    dfres.to_csv(f\"csv/fscve_unique_crashes_step7metric1_{benchmark}_{fc}.csv\")\n",
    "    # print(dfres)\n",
    "    df_results.append(dfres)\n",
    "\n",
    "#merge two fuzzer combination\n",
    "df_result_benchmark = pd.concat(df_results, ignore_index=True)\n",
    "df_result_drop = df_result_benchmark.drop(dfres.columns.difference(cols_to_keep), axis=1)\n",
    "print(\"*\"*30)\n",
    "print(df_result_drop)\n",
    "print(\"-\"*30)\n",
    "\n",
    "\n",
    "df_unique_crashes_total_count = df_result_drop.groupby([\"benchmark\", \"fuzzer_combination\"])[[\"testcase_hash\"]].count().reset_index(drop=False)\n",
    "# print(df_unique_crashes_total_count)\n",
    "# print(df_unique_crashes_total_count[\"testcase_hash\"])\n",
    "#add column\n",
    "df_result_final_crash_step7metric1=pd.DataFrame()\n",
    "df_result_final_crash_step7metric1[\"benchmark\"]=df_result_drop.drop_duplicates([\"benchmark\", \"fuzzer_combination\"])[\"benchmark\"]\n",
    "df_result_final_crash_step7metric1[\"fuzzer_combination\"]=df_result_drop.drop_duplicates([\"benchmark\", \"fuzzer_combination\"])[\"fuzzer_combination\"]\n",
    "df_result_final_crash_step7metric1[\"total_unique\"]=df_unique_crashes_total_count[\"testcase_hash\"].to_list()\n",
    "df_result_final_crash_step7metric1=df_result_final_crash_step7metric1.reset_index(drop=True)\n",
    "df_result_final_crash_step7metric1.to_csv(f\"csv/fscve_crash_step7metric1_totalunique_{benchmark}.csv\")\n",
    "# print(df_result_final_crash_step7metric1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  benchmark fuzzer_combination  experiment_id  bug_count\n",
      "0     cflow                fca              1          5\n",
      "1     cflow                fca              2          5\n",
      "2     cflow                fca              3          3\n",
      "3     cflow                fca              4          4\n",
      "4     cflow                fca              5          4\n",
      "  benchmark fuzzer_combination  experiment_id  bug_count\n",
      "0     cflow                fcb              1          3\n",
      "1     cflow                fcb              2          4\n",
      "2     cflow                fcb              3          3\n",
      "3     cflow                fcb              4          2\n",
      "4     cflow                fcb              5          4\n"
     ]
    }
   ],
   "source": [
    "#calc for unique real bugs\n",
    "for fc in fcs:\n",
    "    dfs = []\n",
    "    for expid in range(0,expids):\n",
    "        df = pd.read_csv(f\"csv/fscve_crash_analysis_bugcnt_{benchmark}_{fc}_{expid+1}.csv\")\n",
    "        dfs.append(df)\n",
    "    df_bugcnt_all = pd.concat(dfs, ignore_index=True)\n",
    "    cols_to_keep = [\"benchmark\",\"fuzzer_combination\",\"experiment_id\",\"bug_count\"]\n",
    "    df_bugcnt_all.drop(df_bugcnt_all.columns.difference(cols_to_keep), axis=1, inplace=True)\n",
    "    print(df_bugcnt_all)\n",
    "    path_bugcnt_all_csv = f\"csv/fscve_crash_analysis_bugcnt_{benchmark}_{fc}_all.csv\"\n",
    "    df_bugcnt_all.to_csv(path_bugcnt_all_csv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['experiment_id_1', 'experiment_id_2', 'experiment_id_3', 'experiment_id_4', 'experiment_id_5', 'experiment_id_1', 'experiment_id_2', 'experiment_id_3', 'experiment_id_4', 'experiment_id_5']\n",
      "********************\n",
      "\n",
      "  benchmark fuzzer_combination  experiment_id_1  experiment_id_2  \\\n",
      "0     cflow                fca                5                5   \n",
      "0     cflow                fcb                3                4   \n",
      "\n",
      "   experiment_id_3  experiment_id_4  experiment_id_5  max  avg  \n",
      "0                3                4                4    5    4  \n",
      "0                3                2                4    4    3  \n"
     ]
    }
   ],
   "source": [
    "#aggregate the bugcount data of repeated experiments ,the bugs are surely not unique ,only to represent the ability of a fuzzer combination on a benchmark during all the repeated times\n",
    "df = pd.DataFrame()\n",
    "dfres = pd.DataFrame()\n",
    "cols_to_keep = [\"benchmark\",\"fuzzer_combination\"]\n",
    "df_results = []\n",
    "#calc all data of a fuzzer combination on one benchmark\n",
    "for fc in fcs:\n",
    "    for expid in range(0,expids):\n",
    "        df = pd.read_csv(f\"csv/fscve_crash_analysis_bugcnt_{benchmark}_{fc}_{expid+1}.csv\")\n",
    "        df[f\"experiment_id_{expid + 1}\"] = df.loc[0,\"bug_count\"]\n",
    "        cols_to_keep.append(f\"experiment_id_{expid + 1}\")\n",
    "        # print(df)\n",
    "        dfres.drop(dfres.columns.difference(cols_to_keep), axis=1, inplace=True)\n",
    "        if expid > 0:\n",
    "            dfres = pd.merge(dfres, df, on=[\"benchmark\",\"fuzzer_combination\"])\n",
    "        else :\n",
    "            dfres = df\n",
    "    dfres.drop(dfres.columns.difference(cols_to_keep), axis=1, inplace=True)\n",
    "    dfres.to_csv(f\"csv/fscve_crash_analysis_bugcnt_{benchmark}_{fc}.csv\")\n",
    "    # print(dfres)\n",
    "    df_results.append(dfres)\n",
    "\n",
    "#merge two fuzzer combination\n",
    "df_result_final_bugcnt = pd.concat(df_results)\n",
    "cols_to_keep.remove(\"benchmark\")\n",
    "cols_to_keep.remove(\"fuzzer_combination\")\n",
    "print(cols_to_keep)\n",
    "print(\"*\"*20)\n",
    "print()\n",
    "#dron non-digit columns for calculating\n",
    "df_result_drop = df_result_final_bugcnt.drop(dfres.columns.difference(cols_to_keep), axis=1)\n",
    "# print(df_result_final)\n",
    "# print(\"*\"*30)\n",
    "# print(df_result_drop)\n",
    "# print(\"-\"*30)\n",
    "df_result_final_bugcnt[\"max\"] = df_result_drop.max(axis=1)\n",
    "df_result_final_bugcnt[\"avg\"] = df_result_drop.mean(axis=1)\n",
    "df_result_final_bugcnt[\"avg\"] = df_result_final_bugcnt[\"avg\"].map(lambda x:int(x))  #float to int\n",
    "print(df_result_final_bugcnt)\n",
    "df_result_final_bugcnt.to_csv(f\"csv/fscve_crash_analysis_bugcnt_repeated_{benchmark}.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    discovery_time                 crash_frames_hash fuzzer_combination\n",
      "0                5  9c74ce5d00fb534a6644db103f1bfe0b                fca\n",
      "1               33  99fad7a3b490f7d3d7fc13b4db848e11                fca\n",
      "2              122  bf39470c4385d389d7814248ff4d17c1                fca\n",
      "3              626  333b4b08bdbba43f4ade91fe58aa064e                fca\n",
      "4             1289  097576036382d7d2b774623b1844285b                fca\n",
      "6              192  0385fd953418b4a9a73109965ed568c1                fca\n",
      "15             861  c35e68ad11ee23588788f0dd3a2c0d73                fca\n",
      "    discovery_time                 crash_frames_hash fuzzer_combination\n",
      "0               10  9c74ce5d00fb534a6644db103f1bfe0b                fcb\n",
      "1              231  bf39470c4385d389d7814248ff4d17c1                fcb\n",
      "2              501  5cb48614635b636e96efbb73c8add63f                fcb\n",
      "5              401  d05f359b27234cc1572a4c4af1b79e43                fcb\n",
      "6             1014  99fad7a3b490f7d3d7fc13b4db848e11                fcb\n",
      "15            1311  0385fd953418b4a9a73109965ed568c1                fcb\n",
      "   discovery_time                 crash_frames_hash fuzzer_combination\n",
      "0               5  9c74ce5d00fb534a6644db103f1bfe0b                fca\n",
      "1              33  99fad7a3b490f7d3d7fc13b4db848e11                fca\n",
      "2             122  bf39470c4385d389d7814248ff4d17c1                fca\n",
      "3             192  0385fd953418b4a9a73109965ed568c1                fca\n",
      "  fuzzer_combination  bugcnt_findfirst\n",
      "0                fca                 4\n"
     ]
    }
   ],
   "source": [
    "#calc for unique real bug ,the time of bug find first , and calc the total number of unique real bugs of a fuzzer combination on one benchmark during all the repeated times\n",
    "df = pd.DataFrame()\n",
    "dfres = pd.DataFrame()\n",
    "cols_to_keep = [\"discovery_time\",\"crash_frames_hash\"]\n",
    "df_results = []\n",
    "#calc all data of a fuzzer combination on one benchmark\n",
    "dict_unique_bugcnt = [] #unique bug count of one fuzzer combination\n",
    "for fc in fcs:\n",
    "    dfs = []\n",
    "    for expid in range(0,expids):\n",
    "        df = pd.read_csv(f\"csv/fscve_crash_analysis_bugfindfirsttime_{benchmark}_{fc}_{expid+1}.csv\")\n",
    "        df.drop(df.columns.difference(cols_to_keep), axis=1, inplace=True)\n",
    "        dfs.append(df)\n",
    "    dfres=pd.concat(dfs, ignore_index=True)\n",
    "    dfres = dfres.drop_duplicates(['crash_frames_hash']) #record once for special fuzzer and real bug\n",
    "    dfres.to_csv(f\"csv/fscve_crash_analysis_bugfindfirsttime_{benchmark}_{fc}.csv\")\n",
    "    dict_unique_bugcnt.append(dfres.shape[0])\n",
    "\n",
    "    dfres[\"fuzzer_combination\"] = [f\"{fc}\" for i in range(0,dfres.shape[0])]\n",
    "    print(dfres)\n",
    "    df_results.append(dfres)\n",
    "\n",
    "# calc the total number of unique real bugs of a fuzzer combination on one benchmark during all the repeated times\n",
    "df_result_final_bugcnt[\"unique_bugcnt\"] = dict_unique_bugcnt\n",
    "#print(df_result_final_bugcnt)\n",
    "df_result_final_bugcnt.to_csv(f\"csv/fscve_crash_analysis_bugcnt_unique_{benchmark}.csv\")\n",
    "\n",
    "\n",
    "#merge two fuzzer combination to decide which fuzzer combination finds the same special bug faster\n",
    "df_result_final_bugfindfirsttime = pd.concat(df_results)\n",
    "\n",
    "#keep the same bugs --> sort by bug and time --->  drop duplicate ---> sort by time\n",
    "df_result_final_bugfindfirsttime = df_result_final_bugfindfirsttime[df_result_final_bugfindfirsttime.duplicated('crash_frames_hash', keep=False)].sort_values(['crash_frames_hash',\"discovery_time\"]).drop_duplicates(['crash_frames_hash']).sort_values([\"discovery_time\"]).reset_index(drop=True)\n",
    "print(df_result_final_bugfindfirsttime)\n",
    "df_result_final_bugfindfirsttime.to_csv(f\"csv/fscve_crash_analysis_bugdetail_findfirst_{benchmark}.csv\")\n",
    "\n",
    "#add column\n",
    "df_result_final_bugfindfirsttime[\"bugcnt_findfirst\"]=df_result_final_bugfindfirsttime[\"fuzzer_combination\"]\n",
    "df_result_final_bugfindfirsttime = df_result_final_bugfindfirsttime.groupby(\"fuzzer_combination\")[[\"bugcnt_findfirst\"]].count().reset_index(drop=False)\n",
    "\n",
    "df_result_final_bugfindfirsttime.to_csv(f\"csv/fscve_crash_analysis_bugcnt_findfirst_{benchmark}.csv\")\n",
    "print(df_result_final_bugfindfirsttime)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for the same special bug,which fuzzer  combination finds\n",
    "# #dron non-digit columns for calculating\n",
    "# df_result_drop = df_result_final.drop(dfres.columns.difference(cols_to_keep), axis=1)\n",
    "# # print(df_result_final)\n",
    "# # print(\"*\"*30)\n",
    "# # print(df_result_drop)\n",
    "# # print(\"-\"*30)\n",
    "# df_result_final[\"max\"] = df_result_drop.max(axis=1)\n",
    "# df_result_final[\"avg\"] = df_result_drop.sum(axis=1)//expids\n",
    "# print(df_result_final)\n",
    "# df_result_final.to_csv(f\"csv/fscve_crash_analysis_bugcnt_final_{benchmark}.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}