{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# calculate tables of edge coverage\n",
    "benchmark = \"cflow\"\n",
    "expids = 10  #repeated times\n",
    "fc = \"fcb\"\n",
    "benchmarks = {\"cflow\", \"jq\", \"mp42aac\", \"nm\", \"objdump\", \"readelf\", \"libpng\",  \"libxml2\", \"openssl\", \"lua\"}\n",
    "fcs = {\"fca\", \"fcb\"}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  benchmark fuzzer_combination  experiment_id  edge_count\n",
      "0     cflow                fcb              1         172\n",
      "1     cflow                fcb              2         172\n",
      "2     cflow                fcb              3         167\n",
      "3     cflow                fcb              4         168\n",
      "4     cflow                fcb              5         169\n",
      "5     cflow                fcb              6         167\n",
      "6     cflow                fcb              7         174\n",
      "7     cflow                fcb              8         177\n",
      "8     cflow                fcb              9         161\n",
      "9     cflow                fcb             10         177\n",
      "  benchmark fuzzer_combination  experiment_id  edge_count\n",
      "0     cflow                fca              1         185\n",
      "1     cflow                fca              2         178\n",
      "2     cflow                fca              3         184\n",
      "3     cflow                fca              4         171\n",
      "4     cflow                fca              5         175\n",
      "5     cflow                fca              6         190\n",
      "6     cflow                fca              7         177\n",
      "7     cflow                fca              8         180\n",
      "8     cflow                fca              9         177\n",
      "9     cflow                fca             10         174\n"
     ]
    }
   ],
   "source": [
    "#alc the global edge coverage for repeaded experiments\n",
    "for fc in fcs:\n",
    "    dfs = []\n",
    "    for expid in range(0,expids):\n",
    "        df = pd.read_csv(f\"csv/fscve_edge_count_global_{benchmark}_{fc}_{expid+1}.csv\")\n",
    "        dfs.append(df)\n",
    "    df_edge_count_global_all = pd.concat(dfs, ignore_index=True)\n",
    "    cols_to_keep = [\"benchmark\",\"fuzzer_combination\",\"experiment_id\",\"edge_count\"]\n",
    "    df_edge_count_global_all.drop(df_edge_count_global_all.columns.difference(cols_to_keep), axis=1, inplace=True)\n",
    "    print(df_edge_count_global_all)\n",
    "    df_edge_count_global_all.to_csv(f\"csv/fscve_edge_count_global_{benchmark}_{fc}_all.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  benchmark fuzzer_combination  experiment_id_1  experiment_id_2  \\\n",
      "0     cflow                fcb              172              172   \n",
      "1     cflow                fca              185              178   \n",
      "\n",
      "   experiment_id_3  experiment_id_4  experiment_id_5  experiment_id_6  \\\n",
      "0              167              168              169              167   \n",
      "1              184              171              175              190   \n",
      "\n",
      "   experiment_id_7  experiment_id_8  experiment_id_9  experiment_id_10  max  \\\n",
      "0              174              177              161               177  177   \n",
      "1              177              180              177               174  190   \n",
      "\n",
      "   avg  \n",
      "0  170  \n",
      "1  179  \n"
     ]
    }
   ],
   "source": [
    "dfres = pd.DataFrame()\n",
    "df = pd.DataFrame()\n",
    "cols_to_keep = [\"benchmark\",\"fuzzer_combination\"]\n",
    "df_results = []\n",
    "#calc all data of a fuzzer combination on one benchmark\n",
    "for fc in fcs:\n",
    "    for expid in range(0,expids):\n",
    "        df = pd.read_csv(f\"csv/fscve_edge_count_global_{benchmark}_{fc}_{expid+1}.csv\")\n",
    "        df[f\"experiment_id_{expid + 1}\"] = df.loc[0,\"edge_count\"]\n",
    "        cols_to_keep.append(f\"experiment_id_{expid + 1}\")\n",
    "        # print(df)\n",
    "        dfres.drop(dfres.columns.difference(cols_to_keep), axis=1, inplace=True)\n",
    "        if expid > 0:\n",
    "            dfres = pd.merge(dfres, df, on=[\"benchmark\",\"fuzzer_combination\"])\n",
    "        else :\n",
    "            dfres = df\n",
    "    dfres.drop(dfres.columns.difference(cols_to_keep), axis=1, inplace=True)\n",
    "    path_unique_crashes_result_csv = f\"csv/fscve_edge_count_global_results_{benchmark}_{fc}.csv\"\n",
    "    dfres.to_csv(path_unique_crashes_result_csv)\n",
    "    # print(dfres)\n",
    "    df_results.append(dfres)\n",
    "\n",
    "#merge two fuzzer combination\n",
    "df_result_final = pd.concat(df_results, ignore_index=True)\n",
    "cols_to_keep.remove(\"benchmark\")\n",
    "cols_to_keep.remove(\"fuzzer_combination\")\n",
    "\n",
    "#dron non-digit columns for calculating\n",
    "df_result_drop = df_result_final.drop(dfres.columns.difference(cols_to_keep), axis=1)\n",
    "# print(df_result_final)\n",
    "# print(\"*\"*30)\n",
    "# print(df_result_drop)\n",
    "# print(\"-\"*30)\n",
    "df_result_final[\"max\"] = df_result_drop.max(axis=1)\n",
    "df_result_final[\"avg\"] = df_result_drop.mean(axis=1)\n",
    "df_result_final[\"avg\"] = df_result_final[\"avg\"].map(lambda x:int(x))  #float to int\n",
    "print(df_result_final)\n",
    "df_result_final.to_csv(f\"csv/fscve_edge_count_global_results_repeated_{benchmark}.csv\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_edge_count_smaller:177\n",
      "  benchmark fuzzer_combination  max_coverage_global_smaller  first_time\n",
      "0     cflow                fcb                          177         804\n",
      "max_edge_count_smaller:177\n",
      "  benchmark fuzzer_combination  max_coverage_global_smaller  first_time\n",
      "0     cflow                fca                          177         151\n",
      "*result**result**result**result**result**result**result**result**result**result**result**result**result**result**result**result**result**result**result**result*\n",
      "  benchmark fuzzer_combination  max_coverage_global_smaller  first_time\n",
      "0     cflow                fcb                          177         804\n",
      "1     cflow                fca                          177         151\n"
     ]
    }
   ],
   "source": [
    "#calc the time when max coverage(the smaller of the two fuzzer combinations) achieved\n",
    "\n",
    "dfres = pd.DataFrame()\n",
    "df = pd.DataFrame()\n",
    "dfs = []\n",
    "cols_to_keep = [\"benchmark\",\"fuzzer_combination\"]\n",
    "df_edge_global_first_time_fcs = []\n",
    "first_time_fcs = []\n",
    "fcs_results = []\n",
    "#calc all data of a fuzzer combination on one benchmark\n",
    "for fc in fcs:\n",
    "    df_result_max_edge_count_global_fc = pd.read_csv(f\"csv/fscve_edge_count_global_results_repeated_{benchmark}.csv\")\n",
    "    df_result_max_edge_count_global_fc.reset_index(drop=True)\n",
    "    # print(df_result_max_edge_count_global_fc)\n",
    "    max_edge_count_smaller = min(df_result_max_edge_count_global_fc.loc[0,\"max\"], df_result_max_edge_count_global_fc.loc[1,\"max\"])\n",
    "    print(f\"max_edge_count_smaller:{max_edge_count_smaller}\")\n",
    "    dfs = []\n",
    "    for expid in range(0,expids):\n",
    "        df = pd.read_csv(f\"csv/fscve_edge_history_global_{benchmark}_{fc}_{expid+1}.csv\")\n",
    "        dfs.append(df)\n",
    "    df_edge_history_global_onefc = pd.concat(dfs, ignore_index=True).sort_values(by=[\"edges_count\",\"time\"])\n",
    "    #edge coverage global history of one fuzzer combinations\n",
    "    # df_edge_history_global_onefc.to_csv(f\"csv/fscve_edge_history_global_{benchmark}_{fc}.csv\")\n",
    "    # print(df_edge_history_global_onefc)\n",
    "\n",
    "\n",
    "    #calc the time when max coverage(the smaller of the two fuzzer combinations) achieved by one fuzzer combination(fc)\n",
    "    first_time_fc = df_edge_history_global_onefc[df_edge_history_global_onefc['edges_count']>=max_edge_count_smaller].head(1).iloc[0,3]\n",
    "    df_edge_global_first_time_fc=pd.DataFrame()\n",
    "    df_edge_global_first_time_fc[\"benchmark\"]=[benchmark]\n",
    "    df_edge_global_first_time_fc[\"fuzzer_combination\"]=[fc]\n",
    "    df_edge_global_first_time_fc[\"max_coverage_global_smaller\"]=[max_edge_count_smaller]\n",
    "    df_edge_global_first_time_fc[\"first_time\"]=[first_time_fc]\n",
    "    df_edge_global_first_time_fc.to_csv(f\"csv/fscve_edge_global_results_firsttime_{benchmark}_{fc}.csv\")\n",
    "    print(df_edge_global_first_time_fc)\n",
    "    df_edge_global_first_time_fcs.append(df_edge_global_first_time_fc)\n",
    "\n",
    "#merge two fuzzer combination\n",
    "print(\"*result*\"*20)\n",
    "df_edge_global_first_time_result = pd.concat(df_edge_global_first_time_fcs, ignore_index=True)\n",
    "print(df_edge_global_first_time_result)\n",
    "df_edge_global_first_time_result.to_csv(f\"csv/fscve_edge_global_results_firsttime_{benchmark}.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       edges_count  time  experiment_id\n",
      "0              102     0              1\n",
      "1              109     1              1\n",
      "2              111     2              1\n",
      "3              116     3              1\n",
      "4              120     4              1\n",
      "...            ...   ...            ...\n",
      "14304          177  1435             10\n",
      "14305          177  1436             10\n",
      "14306          177  1437             10\n",
      "14307          177  1438             10\n",
      "14308          177  1439             10\n",
      "\n",
      "[14309 rows x 3 columns]\n",
      "       edges_count  time  experiment_id\n",
      "0              118     0              1\n",
      "1              131     1              1\n",
      "2              132     2              1\n",
      "3              132     3              1\n",
      "4              132     4              1\n",
      "...            ...   ...            ...\n",
      "14376          174  1432             10\n",
      "14377          174  1433             10\n",
      "14378          174  1434             10\n",
      "14379          174  1435             10\n",
      "14380          174  1436             10\n",
      "\n",
      "[14381 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#calc the global edge history of the repeated experiments on a special benchmark\n",
    "#for drawing history curve graph\n",
    "#draw the comparing graph of two fuzzer combinations on itself's 10 repeated times\n",
    "df = pd.DataFrame()\n",
    "dfs = []\n",
    "cols_to_keep_history_global = [\"edges_count\",\"time\", \"experiment_id\"]\n",
    "df_edge_global_first_time_fcs = []\n",
    "#calc all data of a fuzzer combination on one benchmark\n",
    "for fc in fcs:\n",
    "    dfs = []\n",
    "    for expid in range(0,expids):\n",
    "        df = pd.read_csv(f\"csv/fscve_edge_history_global_{benchmark}_{fc}_{expid+1}.csv\")\n",
    "        df[\"experiment_id\"]=[expid+1 for i in range(0,df.shape[0])]\n",
    "        dfs.append(df)\n",
    "    df_edge_history_global_onefc = pd.concat(dfs, ignore_index=True).sort_values(by=[\"experiment_id\",\"edges_count\",\"time\"])\n",
    "    df_edge_history_global_onefc = df_edge_history_global_onefc.drop(df_edge_history_global_onefc.columns.difference(cols_to_keep_history_global), axis=1)\n",
    "    #edge coverage global history of one fuzzer combinations\n",
    "    df_edge_history_global_onefc.to_csv(f\"csv/fscve_edge_history_global_{benchmark}_{fc}.csv\")\n",
    "    print(df_edge_history_global_onefc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaa 6775\n",
      "bbbbbb 826\n",
      "                fuzzer         edge fuzzer_combination benchmark\n",
      "0         afl-0-exid21  10016-10021                fcb     cflow\n",
      "1         afl-0-exid21  10021-10030                fcb     cflow\n",
      "2         afl-0-exid21    1004-2468                fcb     cflow\n",
      "3    fairfuzz-0-exid22  10040-10046                fcb     cflow\n",
      "4         afl-0-exid23  10040-10071                fcb     cflow\n",
      "..                 ...          ...                ...       ...\n",
      "821   aflfast-0-exid20    9938-9955                fcb     cflow\n",
      "822       afl-0-exid20    9955-9963                fcb     cflow\n",
      "823   aflfast-0-exid21    9963-9976                fcb     cflow\n",
      "824       afl-0-exid21    9976-9991                fcb     cflow\n",
      "825       afl-0-exid20   9991-10030                fcb     cflow\n",
      "\n",
      "[826 rows x 4 columns]\n",
      "aaaaa 6839\n",
      "bbbbbb 819\n",
      "                  fuzzer         edge fuzzer_combination benchmark\n",
      "0    aflplusplus-0-exid1  10016-10021                fca     cflow\n",
      "1    aflplusplus-0-exid1  10021-10030                fca     cflow\n",
      "2    aflplusplus-0-exid1    1004-2468                fca     cflow\n",
      "3           mopt-0-exid4  10046-10101                fca     cflow\n",
      "4    aflplusplus-0-exid2  10054-10056                fca     cflow\n",
      "..                   ...          ...                ...       ...\n",
      "814         mopt-0-exid2    9938-9955                fca     cflow\n",
      "815  aflplusplus-0-exid2    9955-9963                fca     cflow\n",
      "816     fairfuzz-0-exid2    9963-9976                fca     cflow\n",
      "817  aflplusplus-0-exid1    9976-9991                fca     cflow\n",
      "818  aflplusplus-0-exid0   9991-10030                fca     cflow\n",
      "\n",
      "[819 rows x 4 columns]\n",
      "1645\n",
      "****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_22020/4024279363.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_edge_detail_onefc_no_duplicates[\"fuzzer_combination\"] = fc\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_22020/4024279363.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_edge_detail_onefc_no_duplicates[\"benchmark\"] = benchmark\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_22020/4024279363.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_edge_detail_onefc_no_duplicates[\"fuzzer_combination\"] = fc\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_22020/4024279363.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_edge_detail_onefc_no_duplicates[\"benchmark\"] = benchmark\n"
     ]
    }
   ],
   "source": [
    "#complementary measurement\n",
    "#step1:search the edges that the two fuzzer combinations have found in common on a benchmark in all repeated experiments\n",
    "#      merge the results of repeated experiments of a fuzzer combination（fc）on  a benchmark, collect the times each edge has been found by one fuzzer\n",
    "\n",
    "#step2:for each fuzzer combination(fc) ,calc its complementary measurement,by the formulation:  sum(1-II(1-pi))\n",
    "import re\n",
    "dfs_benchmark = []\n",
    "cols_to_keep_edge_detail = [\"fuzzer\", \"edge\"]\n",
    "# df_edge_detail_fcs = []\n",
    "df_edge_detail_fcs_no_dulicates = []\n",
    "dict_fc_dataframe_detail = {}\n",
    "dict_results_complemetary_measurement={}\n",
    "dict_values_fc = []\n",
    "dict_values_complemetary_measurement = []\n",
    "#calc all data of a fuzzer combination on one benchmark\n",
    "for fc in fcs:\n",
    "    dfs = []\n",
    "    for expid in range(0,expids):\n",
    "        df = pd.read_csv(f\"csv/fscve_edge_detail_{benchmark}_{fc}_{expid+1}.csv\")\n",
    "        df[\"edge\"] = df[\"block_source\"].astype(\"str\") + df[\"block_target\"].astype(\"str\").map(lambda x:\"-\"+x)\n",
    "        dfs.append(df)\n",
    "        # print(df)\n",
    "    df_edge_detail_onefc = pd.concat(dfs, ignore_index=True)\n",
    "    df_edge_detail_onefc = df_edge_detail_onefc.drop(df_edge_detail_onefc.columns.difference(cols_to_keep_edge_detail), axis=1).sort_values(by=[\"edge\",\"fuzzer\"])\n",
    "\n",
    "    #edge coverage global history of one fuzzer combinations\n",
    "    df_edge_detail_onefc.to_csv(f\"csv/fscve_edge_detail_{benchmark}_{fc}.csv\")\n",
    "    #print(df_edge_detail_onefc)\n",
    "    # df_edge_detail_fcs.append(df_edge_detail_onefc)\n",
    "    dict_fc_dataframe_detail[fc]=df_edge_detail_onefc\n",
    "\n",
    "    #delete duplicated edges for every fuzzer combination\n",
    "    print(\"aaaaa\", df_edge_detail_onefc.shape[0])\n",
    "    df_edge_detail_onefc_no_duplicates = df_edge_detail_onefc.drop_duplicates(['edge'])\n",
    "    print(\"bbbbbb\", df_edge_detail_onefc_no_duplicates.shape[0])\n",
    "    df_edge_detail_onefc_no_duplicates[\"fuzzer_combination\"] = fc\n",
    "    df_edge_detail_onefc_no_duplicates[\"benchmark\"] = benchmark\n",
    "    df_edge_detail_onefc_no_duplicates=df_edge_detail_onefc_no_duplicates.reset_index(drop=True)\n",
    "    print(df_edge_detail_onefc_no_duplicates)\n",
    "    df_edge_detail_fcs_no_dulicates.append(df_edge_detail_onefc_no_duplicates)\n",
    "\n",
    "#all edge detail on b benchmark from fca and fcb  ，each of them has no duplicated edge\n",
    "df_edge_detail_benchmark_no_dulicates = pd.concat(df_edge_detail_fcs_no_dulicates, ignore_index=True)\n",
    "df_edge_detail_benchmark_no_dulicates.to_csv(f\"csv/fscve_edge_detail_{benchmark}.csv\")\n",
    "print(df_edge_detail_benchmark_no_dulicates.shape[0])\n",
    "print(\"**\"*20)\n",
    "\n",
    "# #common edges of fca and fcb\n",
    "# df_edge_detail_benchmark_common = df_edge_detail_benchmark_no_dulicates[df_edge_detail_benchmark_no_dulicates.duplicated('edge', keep=False)]\n",
    "# list_edge_common = df_edge_detail_benchmark_common[\"edge\"].to_list()\n",
    "# # print(list_edge_common)\n",
    "# # print(df_edge_detail_benchmark_common)\n",
    "# # print(df_edge_detail_benchmark_common.shape[0])\n",
    "#\n",
    "# print(\"--\"*20)\n",
    "# #all edge detail on b benchmark from fca and fcb\n",
    "# # df_edge_detail_benchmark = pd.concat(df_edge_detail_fcs, ignore_index=True)\n",
    "# # print(df_edge_detail_benchmark.shape[0])\n",
    "#\n",
    "# #calc the fuzzer combination's complementary measurement on a benchmakr during all of the repeated experiments\n",
    "# for fc in fcs:\n",
    "#     df_detail_fc_measurement = dict_fc_dataframe_detail[fc]\n",
    "#     df_detail_fc_measurement['fuzzer'] = df_detail_fc_measurement['fuzzer'].map(lambda x : re.findall(r\"(.+?)-exid\\d+\",x)[0])\n",
    "#     # print(df_detail_fc.shape[0])\n",
    "#     # print(df_detail_fc_measurement)\n",
    "#     # print(df_detail_fc[df_detail_fc[\"edge\"].isin(df_edge_detail_benchmark_common[\"edge\"])].shape[0])\n",
    "#     df_detail_fc_measurement=df_detail_fc_measurement[df_detail_fc_measurement[\"edge\"].isin(df_edge_detail_benchmark_common[\"edge\"])] #dataframe with edges in common\n",
    "#     count_series=df_detail_fc_measurement.groupby(by=[\"fuzzer\",\"edge\"]).size()  #group and get the count of the same column value composition\n",
    "#     # print(count_series)\n",
    "#     df_detail_fc_measurement = count_series.to_frame(name = 'times').reset_index()\n",
    "#     # df_detail_fc_measurement = df_detail_fc_measurement[df_detail_fc_measurement[\"times\"]>1]\n",
    "#     print(df_detail_fc_measurement)\n",
    "#\n",
    "#\n",
    "#     #step2 is coming\n",
    "#     edges = df_detail_fc_measurement[\"edge\"].unique().tolist()\n",
    "#     edge_complementary_measurement_fc = 0\n",
    "#     for edge in edges:\n",
    "#         #lc the probability to cover a special edge\n",
    "#         fuzzers = df_detail_fc_measurement[\"fuzzer\"].unique().tolist()\n",
    "#         pe = 1\n",
    "#\n",
    "#         for fuzzer in fuzzers:\n",
    "#             # print(f\"{fuzzer}----{edge}\")\n",
    "#             tmp = df_detail_fc_measurement[(df_detail_fc_measurement[\"fuzzer\"]==f\"{fuzzer}\") & (df_detail_fc_measurement[\"edge\"]==f\"{edge}\")]\n",
    "#             # print(tmp)\n",
    "#             # print(tmp.empty)\n",
    "#             if tmp.empty or (pd.isnull(tmp.iloc[0, 2])): #3---times\n",
    "#                continue\n",
    "#             pe = pe * (1-tmp.iloc[0,2]/expids)\n",
    "#\n",
    "#         edge_complementary_measurement_fc = edge_complementary_measurement_fc + 1-pe\n",
    "#     dict_values_fc.append(fc)\n",
    "#     dict_values_complemetary_measurement.append(edge_complementary_measurement_fc)    #store the measurement metric\n",
    "#\n",
    "# dict_results_complemetary_measurement[\"fuzzer_combination\"]=dict_values_fc\n",
    "# dict_results_complemetary_measurement[\"complemetary_metric\"]=dict_values_complemetary_measurement\n",
    "# df_results_complemetary_measurement = pd.DataFrame(dict_results_complemetary_measurement)\n",
    "# print(df_results_complemetary_measurement)\n",
    "# df_results_complemetary_measurement.to_csv(f\"csv/fscve_edge_results_complemetary_metric_{benchmark}_old.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairfuzz-0\n"
     ]
    }
   ],
   "source": [
    "s=\"fairfuzz-0-exid24\"\n",
    "print(s[:s.rindex(\"-exid\")])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "----------------------------------------\n",
      "          fuzzer         edge  times\n",
      "0          afl-0  10016-10021      4\n",
      "1          afl-0  10021-10030      2\n",
      "2          afl-0    1004-2468      2\n",
      "3          afl-0  10040-10071      1\n",
      "4          afl-0  10040-10086      1\n",
      "...          ...          ...    ...\n",
      "2264  fairfuzz-0    9903-9907      1\n",
      "2265  fairfuzz-0    9914-9924      1\n",
      "2266  fairfuzz-0    9932-9938      1\n",
      "2267  fairfuzz-0    9955-9963      2\n",
      "2268  fairfuzz-0    9963-9976      3\n",
      "\n",
      "[2269 rows x 3 columns]\n",
      "             fuzzer         edge  times\n",
      "0     aflplusplus-0  10016-10021      3\n",
      "1     aflplusplus-0  10021-10030      4\n",
      "2     aflplusplus-0    1004-2468      4\n",
      "3     aflplusplus-0  10054-10056      1\n",
      "4     aflplusplus-0  10056-10064      2\n",
      "...             ...          ...    ...\n",
      "2258        symcc-0    9907-9914      3\n",
      "2259        symcc-0    9938-9955      2\n",
      "2260        symcc-0    9955-9963      1\n",
      "2261        symcc-0    9976-9991      1\n",
      "2262        symcc-0   9991-10030      1\n",
      "\n",
      "[2263 rows x 3 columns]\n",
      "  fuzzer_combination  complemetary_metric\n",
      "0                fcb             0.406058\n",
      "1                fca             0.408873\n"
     ]
    }
   ],
   "source": [
    "#complementary measurement\n",
    "#step1:search the edges that the two fuzzer combinations have found in total on a benchmark in all repeated experiments  ,that is fca:1,2,3,3  fcb:1,3,4,5,  ,the total unique element 1,2,3,4,5 would be collected\n",
    "#      merge the results of repeated experiments of a fuzzer combination（fc）on  a benchmark, collect the times each edge has been found by one fuzzer\n",
    "\n",
    "#step2:for each fuzzer combination(fc) ,calc its complementary measurement,by the formulation:  sum(1-II(1-pi))\n",
    "\n",
    "print(\"**\"*20)\n",
    "\n",
    "#common edges of fca and fcb\n",
    "df_edge_detail_benchmark_common = df_edge_detail_benchmark_no_dulicates.drop_duplicates(['edge'])\n",
    "list_edge_common = df_edge_detail_benchmark_common[\"edge\"].to_list()\n",
    "# print(list_edge_common)\n",
    "# print(df_edge_detail_benchmark_common)\n",
    "# print(df_edge_detail_benchmark_common.shape[0])\n",
    "\n",
    "print(\"--\"*20)\n",
    "#all edge detail on b benchmark from fca and fcb\n",
    "# df_edge_detail_benchmark = pd.concat(df_edge_detail_fcs, ignore_index=True)\n",
    "# print(df_edge_detail_benchmark.shape[0])\n",
    "\n",
    "#calc the fuzzer combination's complementary measurement on a benchmakr during all of the repeated experiments\n",
    "for fc in fcs:\n",
    "    df_detail_fc_measurement = dict_fc_dataframe_detail[fc]\n",
    "    df_detail_fc_measurement['fuzzer'] = df_detail_fc_measurement['fuzzer'].map(lambda x : re.findall(r\"(.+?)-exid\\d+\",x)[0])\n",
    "    # print(df_detail_fc.shape[0])\n",
    "    # print(df_detail_fc_measurement)\n",
    "    # print(df_detail_fc[df_detail_fc[\"edge\"].isin(df_edge_detail_benchmark_common[\"edge\"])].shape[0])\n",
    "    df_detail_fc_measurement=df_detail_fc_measurement[df_detail_fc_measurement[\"edge\"].isin(df_edge_detail_benchmark_common[\"edge\"])] #dataframe with edges in common\n",
    "    count_series=df_detail_fc_measurement.groupby(by=[\"fuzzer\",\"edge\"]).size()  #group and get the count of the same column value composition\n",
    "    # print(count_series)\n",
    "    df_detail_fc_measurement = count_series.to_frame(name = 'times').reset_index()\n",
    "    # df_detail_fc_measurement = df_detail_fc_measurement[df_detail_fc_measurement[\"times\"]>1]\n",
    "    print(df_detail_fc_measurement)\n",
    "\n",
    "\n",
    "    #step2 is coming\n",
    "    edges = df_detail_fc_measurement[\"edge\"].unique().tolist()\n",
    "    edge_complementary_measurement_fc = 0\n",
    "    for edge in edges:\n",
    "        #lc the probability to cover a special edge\n",
    "        fuzzers = df_detail_fc_measurement[\"fuzzer\"].unique().tolist()\n",
    "        pe = 1\n",
    "\n",
    "        for fuzzer in fuzzers:\n",
    "            # print(f\"{fuzzer}----{edge}\")\n",
    "            tmp = df_detail_fc_measurement[(df_detail_fc_measurement[\"fuzzer\"]==f\"{fuzzer}\") & (df_detail_fc_measurement[\"edge\"]==f\"{edge}\")]\n",
    "            # print(tmp)\n",
    "            # print(tmp.empty)\n",
    "            if tmp.empty or (pd.isnull(tmp.iloc[0, 2])): #3---times\n",
    "                continue\n",
    "            pe = pe * (1-tmp.iloc[0,2]/expids)\n",
    "\n",
    "        edge_complementary_measurement_fc = edge_complementary_measurement_fc + 1-pe\n",
    "    dict_values_fc.append(fc)\n",
    "    dict_values_complemetary_measurement.append(edge_complementary_measurement_fc)    #store the measurement metric\n",
    "\n",
    "dict_results_complemetary_measurement[\"fuzzer_combination\"]=dict_values_fc\n",
    "dict_results_complemetary_measurement[\"complemetary_metric\"]=dict_values_complemetary_measurement\n",
    "df_results_complemetary_measurement = pd.DataFrame(dict_results_complemetary_measurement)\n",
    "df_results_complemetary_measurement[\"complemetary_metric\"] = df_results_complemetary_measurement[\"complemetary_metric\"].apply(lambda x : x/len(list_edge_common))\n",
    "print(df_results_complemetary_measurement)\n",
    "df_results_complemetary_measurement.to_csv(f\"csv/fscve_edge_results_complemetary_metric_{benchmark}.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "serie_results=pd.Series(dict_results_complemetary_measurement).to_csv(\"tmp.csv\")\n",
    "print(serie_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1704\n",
      "560\n",
      "  benchmark fuzzer_combination  total_unique\n",
      "0     cflow                fcb           560\n",
      "1791\n",
      "565\n",
      "  benchmark fuzzer_combination  total_unique\n",
      "0     cflow                fca           565\n"
     ]
    }
   ],
   "source": [
    "#calc the total unique edges of a fc on special benchmark\n",
    "#for enfuzz,the old data collected didn't include edge-coverage-fuzzer db table\n",
    "#so,it needs to obtain the info from edge-coverage-global,instead of fscve_edge_detail_{benchmark}_{fc}_{expid}.csv\n",
    "for fc in fcs:\n",
    "    dfs = []\n",
    "    for expid in range(0,expids):\n",
    "        df = pd.read_csv(f\"csv/fscve_step6_metric1_totalunique_{benchmark}_{fc}_{expid+1}.csv\")\n",
    "        dfs.append(df)\n",
    "\n",
    "    df_edge_total_unique_tmp= pd.concat(dfs, ignore_index=True)\n",
    "    print(df_edge_total_unique_tmp.shape[0])\n",
    "    df_edge_total_unique_tmp=df_edge_total_unique_tmp.drop_duplicates(\"edge\")\n",
    "    print(df_edge_total_unique_tmp.shape[0])\n",
    "    df_edge_total_unique = pd.DataFrame({\"benchmark\":[benchmark],\"fuzzer_combination\":[fc],\"total_unique\":[df_edge_total_unique_tmp.shape[0]]})\n",
    "    print(df_edge_total_unique)\n",
    "    df_edge_total_unique.to_csv(f\"csv/fscve_step6_metric1_totalunique_{benchmark}_{fc}_all.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onefc detail-_venn----------------------------------------------------------\n",
      "aaaaa_venn 6775\n",
      "bbbbbb_venn 2269\n",
      "             fuzzer         edge fuzzer_combination benchmark\n",
      "951           afl-0  10016-10021                fcb     cflow\n",
      "3184      aflfast-0  10016-10021                fcb     cflow\n",
      "4482  aflplusplus-0  10016-10021                fcb     cflow\n",
      "279      fairfuzz-0  10016-10021                fcb     cflow\n",
      "4287          afl-0  10021-10030                fcb     cflow\n",
      "...             ...          ...                ...       ...\n",
      "1005          afl-0    9976-9991                fcb     cflow\n",
      "2414      aflfast-0    9976-9991                fcb     cflow\n",
      "349           afl-0   9991-10030                fcb     cflow\n",
      "3854      aflfast-0   9991-10030                fcb     cflow\n",
      "4501  aflplusplus-0   9991-10030                fcb     cflow\n",
      "\n",
      "[2269 rows x 4 columns]\n",
      "onefc detail-_venn----------------------------------------------------------\n",
      "aaaaa_venn 6839\n",
      "bbbbbb_venn 2263\n",
      "             fuzzer         edge fuzzer_combination benchmark\n",
      "874   aflplusplus-0  10016-10021                fca     cflow\n",
      "2366     fairfuzz-0  10016-10021                fca     cflow\n",
      "277         symcc-0  10016-10021                fca     cflow\n",
      "4294  aflplusplus-0  10021-10030                fca     cflow\n",
      "5747     fairfuzz-0  10021-10030                fca     cflow\n",
      "...             ...          ...                ...       ...\n",
      "4507         mopt-0    9976-9991                fca     cflow\n",
      "6457        symcc-0    9976-9991                fca     cflow\n",
      "3925  aflplusplus-0   9991-10030                fca     cflow\n",
      "3847         mopt-0   9991-10030                fca     cflow\n",
      "3732        symcc-0   9991-10030                fca     cflow\n",
      "\n",
      "[2263 rows x 4 columns]\n",
      "4532\n",
      "****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_22020/1626890851.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_edge_detail_onefc_no_duplicates_venn[\"fuzzer_combination\"] = fc\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_22020/1626890851.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_edge_detail_onefc_no_duplicates_venn[\"benchmark\"] = benchmark\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_22020/1626890851.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_edge_detail_onefc_no_duplicates_venn[\"fuzzer_combination\"] = fc\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_22020/1626890851.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_edge_detail_onefc_no_duplicates_venn[\"benchmark\"] = benchmark\n"
     ]
    }
   ],
   "source": [
    "#calc for venn diagram for edge covered by fuzzers\n",
    "import re\n",
    "cols_to_keep_edge_detail_venn = [\"fuzzer\", \"edge\"]\n",
    "df_edge_detail_fcs_no_dulicates_venn = []\n",
    "dict_values_fc_venn = []\n",
    "#calc all data of a fuzzer combination on one benchmark\n",
    "for fc in fcs:\n",
    "    dfs_venn = []\n",
    "    for expid in range(0,expids):\n",
    "        df_venn = pd.read_csv(f\"csv/fscve_edge_detail_{benchmark}_{fc}_{expid+1}.csv\")\n",
    "        df_venn[\"edge\"] = df_venn[\"block_source\"].astype(\"str\") + df_venn[\"block_target\"].astype(\"str\").map(lambda x:\"-\"+x)\n",
    "        dfs_venn.append(df_venn)\n",
    "        # print(df)\n",
    "    df_edge_detail_onefc_venn = pd.concat(dfs_venn, ignore_index=True)\n",
    "    df_edge_detail_onefc_venn = df_edge_detail_onefc_venn.drop(df_edge_detail_onefc_venn.columns.difference(cols_to_keep_edge_detail_venn), axis=1).sort_values(by=[\"edge\",\"fuzzer\"])\n",
    "\n",
    "    #edge coverage global history of one fuzzer combinations\n",
    "    df_edge_detail_onefc_venn.to_csv(f\"csv/fscve_step6_metric3_venn_{benchmark}_{fc}.csv\")\n",
    "    #print(df_edge_detail_onefc)\n",
    "    df_edge_detail_onefc_venn[\"fuzzer\"]=df_edge_detail_onefc_venn[\"fuzzer\"].apply(lambda x:x[:x.rindex(\"-exid\")])\n",
    "    print(\"onefc detail-_venn----------------------------------------------------------\")\n",
    "    #print( df_edge_detail_onefc)\n",
    "    #delete duplicated edges for every fuzzer combination and fuzzer\n",
    "    print(\"aaaaa_venn\", df_edge_detail_onefc_venn.shape[0])\n",
    "    df_edge_detail_onefc_no_duplicates_venn = df_edge_detail_onefc_venn.drop_duplicates(['fuzzer','edge'])\n",
    "    print(\"bbbbbb_venn\", df_edge_detail_onefc_no_duplicates_venn.shape[0])\n",
    "    df_edge_detail_onefc_no_duplicates_venn[\"fuzzer_combination\"] = fc\n",
    "    df_edge_detail_onefc_no_duplicates_venn[\"benchmark\"] = benchmark\n",
    "    #df_edge_detail_onefc_no_duplicates=df_edge_detail_onefc_no_duplicates.reset_index(drop=True)\n",
    "    print(df_edge_detail_onefc_no_duplicates_venn)\n",
    "    df_edge_detail_fcs_no_dulicates_venn.append(df_edge_detail_onefc_no_duplicates_venn)\n",
    "\n",
    "\n",
    "#all edge detail on b benchmark from fca and fcb  ，each of them has no duplicated edge\n",
    "df_edge_detail_benchmark_no_dulicates_venn = pd.concat(df_edge_detail_fcs_no_dulicates_venn, ignore_index=True)\n",
    "df_edge_detail_benchmark_no_dulicates_venn = df_edge_detail_benchmark_no_dulicates_venn.drop(df_edge_detail_benchmark_no_dulicates_venn.columns.difference([\"benchmark\",\"fuzzer_combination\",\"fuzzer\",\"edge\"]), axis=1).sort_values(by=[\"benchmark\",\"fuzzer_combination\",\"fuzzer\",\"edge\"])\n",
    "df_edge_detail_benchmark_no_dulicates_venn.to_csv(f\"csv/fscve_step6_metric3_venn_{benchmark}.csv\")\n",
    "print(df_edge_detail_benchmark_no_dulicates_venn.shape[0])\n",
    "print(\"**\"*20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}